# Multi-Modal Language Model Configuration
# Supports text, audio, vision with OCR weight storage, reasoning, and domain knowledge

model:
  # Core architecture
  d_model: 1024
  n_layers: 24
  n_heads: 16
  d_ff: 4096
  dropout: 0.1
  
  # OCR weight storage
  ocr_enabled: true
  ocr_precision: 8
  weight_compression_ratio: 0.7
  
  # Multi-modal dimensions
  audio_dim: 256
  text_dim: 1024
  vision_dim: 1024
  
  # Language capabilities
  vocab_size: 50000
  max_seq_length: 2048
  reasoning_layers: 4
  domain_knowledge_size: 10000
  
  # Memory and knowledge
  memory_capacity: 50000
  knowledge_base_size: 100000
  context_window: 512

# Training configuration
training:
  # Basic training settings
  batch_size: 4
  learning_rate: 0.001
  weight_decay: 0.01
  num_epochs: 10
  gradient_clip_norm: 1.0
  
  # Progressive training stages
  stages:
    - stage: 1
      d_model: 256
      n_layers: 6
      batch_size: 8
      lr: 0.003
      epochs: 5
    - stage: 2
      d_model: 512
      n_layers: 12
      batch_size: 4
      lr: 0.001
      epochs: 7
    - stage: 3
      d_model: 768
      n_layers: 18
      batch_size: 2
      lr: 0.0005
      epochs: 10
    - stage: 4
      d_model: 1024
      n_layers: 24
      batch_size: 1
      lr: 0.0001
      epochs: 15
  
  # Multi-modal training
  multimodal_training:
    enabled: true
    modality_weights:
      text: 1.0
      audio: 0.8
      vision: 0.8
    
  # OCR training
  ocr_training:
    enabled: true
    ocr_loss_weight: 0.1
    weight_storage_frequency: 100  # Store weights as OCR every N steps
    
  # Domain knowledge training
  domain_training:
    enabled: true
    knowledge_integration_weight: 0.2
    domain_diversity_weight: 0.1

# Reasoning configuration
reasoning:
  # Reasoning types
  logical_reasoning: true
  causal_reasoning: true
  analogical_reasoning: true
  
  # Reasoning parameters
  reasoning_temperature: 1.0
  reasoning_attention_heads: 8
  reasoning_dropout: 0.1
  
  # Reasoning training
  reasoning_training:
    enabled: true
    reasoning_loss_weight: 0.15
    logical_consistency_weight: 0.1
    causal_consistency_weight: 0.1

# Response generation configuration
response_generation:
  # Response types
  greeting_enabled: true
  question_answering_enabled: true
  explanation_enabled: true
  conversation_enabled: true
  
  # Response parameters
  max_response_length: 512
  response_temperature: 0.8
  response_top_p: 0.9
  response_top_k: 50
  
  # Greeting templates
  greeting_templates:
    - "Hello! How can I help you today?"
    - "Hi there! What would you like to know?"
    - "Greetings! I'm here to assist you."
    - "Good day! How may I be of service?"
    - "Hello! I'm ready to help with your questions."

# Domain knowledge configuration
domain_knowledge:
  # Knowledge categories
  categories:
    - "science"
    - "technology"
    - "medicine"
    - "history"
    - "geography"
    - "literature"
    - "mathematics"
    - "philosophy"
    - "art"
    - "sports"
  
  # Knowledge base settings
  knowledge_base:
    max_entries_per_category: 1000
    knowledge_retrieval_limit: 5
    knowledge_similarity_threshold: 0.7
    
  # Knowledge integration
  knowledge_integration:
    enabled: true
    integration_method: "attention"  # attention, concatenation, weighted
    knowledge_weight: 0.3

# Memory management configuration
memory_management:
  # Conversation memory
  conversation_memory:
    enabled: true
    max_memory_length: 100
    memory_retention_days: 30
    
  # OCR weight memory
  ocr_weight_memory:
    enabled: true
    max_weight_images: 1000
    compression_ratio: 0.7
    
  # Domain knowledge memory
  domain_memory:
    enabled: true
    max_knowledge_entries: 10000
    knowledge_update_frequency: 100

# OCR processing configuration
ocr_processing:
  # Image settings
  image:
    width: 1024
    height: 1024
    channels: 3
    format: "RGB"
    
  # Text encoding settings
  text:
    precision_digits: 8
    encoding_scheme: "scientific"  # scientific, decimal, hex, binary
    max_values_per_image: 2000
    font_size: 12
    text_color: "black"
    background_color: "white"
    
  # OCR model settings
  ocr_model:
    primary: "pytesseract"
    fallback: "opencv"
    confidence_threshold: 0.85
    preprocessing:
      resize: true
      denoise: true
      contrast_enhancement: true
      binarization: true
      grayscale: true

# Performance optimization
performance:
  # Multi-modal optimization
  multimodal_optimization:
    parallel_processing: true
    modality_fusion_attention: true
    cross_modal_attention: true
    
  # OCR optimization
  ocr_optimization:
    batch_processing: true
    parallel_ocr: true
    gpu_acceleration: true
    memory_pooling: true
    
  # Memory optimization
  memory_optimization:
    lazy_loading: true
    memory_mapping: true
    compression: true
    caching: true
    
  # Inference optimization
  inference:
    model_compilation: true
    quantization: true
    pruning: true
    dynamic_batching: true

# Evaluation metrics
evaluation:
  # Multi-modal metrics
  multimodal_metrics:
    text_accuracy: true
    audio_reconstruction_loss: true
    vision_reconstruction_loss: true
    cross_modal_consistency: true
    
  # Reasoning metrics
  reasoning_metrics:
    logical_consistency: true
    causal_consistency: true
    analogical_accuracy: true
    reasoning_speed: true
    
  # Response generation metrics
  response_metrics:
    response_quality: true
    response_relevance: true
    response_fluency: true
    response_diversity: true
    
  # Domain knowledge metrics
  knowledge_metrics:
    knowledge_accuracy: true
    knowledge_coverage: true
    knowledge_retrieval_speed: true
    knowledge_integration_quality: true

# Debugging and monitoring
debugging:
  # Multi-modal debugging
  multimodal_debug:
    log_modality_processing: true
    visualize_attention_maps: false
    log_cross_modal_interactions: true
    
  # Reasoning debugging
  reasoning_debug:
    log_reasoning_steps: true
    visualize_reasoning_paths: false
    log_reasoning_confidence: true
    
  # Response debugging
  response_debug:
    log_response_generation: true
    log_domain_knowledge_usage: true
    log_conversation_context: true
    
  # OCR debugging
  ocr_debug:
    save_ocr_images: false
    log_ocr_accuracy: true
    log_weight_storage: true
    
  # Performance monitoring
  performance_monitoring:
    track_inference_time: true
    monitor_memory_usage: true
    log_training_metrics: true
    profile_components: true

# File paths
paths:
  # Model paths
  models:
    multimodal_language_weights: "Model/multimodal_language_weights.safetensors"
    multimodal_language_stages: "Model/multimodal_language_stage_{stage}.safetensors"
    tokenizer: "Model/tokenizer.json"
    
  # Memory storage
  memory_storage:
    conversation_memory: "memory/conversation_memory.json"
    ocr_weight_images: "memory/ocr_weight_images"
    domain_knowledge: "memory/domain_knowledge.json"
    
  # Training data
  training_data:
    text_data: "Dataset/text_data.jsonl"
    audio_data: "Dataset/audio_data.jsonl"
    vision_data: "Dataset/vision_data.jsonl"
    
  # Outputs
  outputs:
    trained_models: "outputs/multimodal_language_models"
    evaluation_results: "outputs/evaluation"
    response_samples: "outputs/response_samples"
    ocr_samples: "outputs/ocr_samples"

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/multimodal_language.log"
  
  # Component-specific logging
  component_logging:
    multimodal_processing: true
    reasoning_engine: true
    response_generation: true
    domain_knowledge: true
    ocr_processing: true
    memory_management: true